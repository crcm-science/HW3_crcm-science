{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2646a34e-a634-47ac-9fe7-73bf40ece8ae",
   "metadata": {},
   "source": [
    "# NOAA Coral Reef Watch's CoralTemp: Dataset Overview and Use Case Example\n",
    "## EDS 220, Fall 2021\n",
    "\n",
    "The following Jupyter notebook demonstrates key features and use case examples for the NOAA Coral Reef Watch CoralTemp dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a405bf-2d38-4175-a931-f52905e11211",
   "metadata": {},
   "source": [
    "## NOAA Coral Reef Watch (CRW) CoralTemp\n",
    "### Using the CoralTemp Dataset for Climate Resilient Coral Modeling (CRCM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc47afd0-adb0-4d5b-8903-992b7904322e",
   "metadata": {},
   "source": [
    "#### Authors\n",
    "\n",
    "- Alex Clippinger, Bren School of Environmental Science & Management, (alexclippinger@ucsb.edu) <br>\n",
    "  https://alexclippinger.github.io/\n",
    "  \n",
    "- Charles Hendrickson, Bren School of Environmental Science & Management,\n",
    "\n",
    "- Connor Flynn, Bren School of Environmental Science & Management,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8c2013-fef1-44ac-bb00-3215807cacac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "[1. Purpose](#purpose)\n",
    "\n",
    "[2. Dataset Description](#overview)\n",
    "\n",
    "[3. Data I/O](#io)\n",
    "\n",
    "[4. Metadata Display and Basic Visualization](#display)\n",
    "\n",
    "[5. Use Case Examples](#usecases)\n",
    "\n",
    "[6. Create Binder Environment](#binder)\n",
    "\n",
    "[7. References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba52c6e3-3584-48be-b500-21578b61bd72",
   "metadata": {},
   "source": [
    "<a id='purpose'></a> \n",
    "### Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d2e353-9a0f-4e68-a897-1899a9f90f9e",
   "metadata": {},
   "source": [
    "This notebook was created to provide an introduction to the NOAA Coral Reef Watch CoralTemp data products, specifically the 5-km sea surface temperature dataset, although we will also introduce the sea surface temperature anomaly and degree heating week datasets. We will demonstrate the capability of these data products to analyze heat resilient coral in the face of warming sea surface temperatures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d429260a-2c30-44da-a5af-e100a440056a",
   "metadata": {},
   "source": [
    "<a id='overview'></a> \n",
    "### Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30571544-7235-4841-b216-b3b4445ecd41",
   "metadata": {},
   "source": [
    "#### Creators of the dataset\n",
    "\n",
    "The CoralTemp data products are maintained by NOAA's Coral Reef Watch Organization (CRW). CRW was established in 2000 to address the need to enhance coral reef resilience. Since then, the organization has accurately monitored and predicted all major bleaching events since 1997. The CoralTemp dataset is the foundation of Coral Reef Watch's ability to fulfill the mission of protecting coral reefs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767c4653-efdf-453a-8203-9ce83000141a",
   "metadata": {},
   "source": [
    "#### Major characteristics\n",
    "\n",
    "CoralTemp is a global sea surface temperature data product used primarily for coral bleaching monitoring. The dataset contains many data products based on 5 geostationary and 3 polar-orbiting satellites. These products include the main sea surface temperature data set (which is the basis for the other products), degree heating week (DHW), bleaching alert areas, coral bleaching hotspots, sea ice fraction, and sea surface temperature anomaly.\n",
    "\n",
    "- Description of data products:\n",
    "  - SST: Nighttime sea surface temperature (celcius), calibrated to 0.2 meters depth, across the entire globe.\n",
    "  - SST Anomaly: A comparison of current sea surface temperature with the long term mean SST at a given location during a certain period of time\n",
    "    - The temperature anomalies range from -5.0 to +5.0 degrees Celsius (°C). Data and images are updated daily\n",
    "  - Degree Heating Week - The DHW shows how much heat stress (SST above the bleaching threshold) has accumulated in an area.\n",
    "    - The units for DHW are \"degree Celsius-weeks\" (or °C-weeks), combining the intensity and duration of the oceanic heat stress into a single number.\n",
    "  - Bleaching Alert Area\n",
    "    - 5 levels (no stress, bleaching warning, bleaching watch, alert level 1, alert level 2)\n",
    "    - Produced based on DHW\n",
    "    \n",
    "We will focus on the primary sea surface temperature (SST) dataset for the remainder of the notebook. The key details of the SST dataset include: \n",
    "- Spatial Resolution: 5km gridded cells.\n",
    "- Spatial Coverage: The dataset has a complete spatial coverage of the ocean. \n",
    "- Temporal Resolution: 1985-04-01 to present. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96be1ce0-3889-457b-860f-7c143f2c6c21",
   "metadata": {},
   "source": [
    "#### File format(s)\n",
    "\n",
    "Data can be downloaded as CSV, netCDF, geotiff, and other common file formats with some unique limitations. For example, geotiff downloads can only contain a single day of data. CSV downloads on the other hand can contain multiple days of observations in a single file. The data is produced daily in near real-time, with an approximately 60 hour delay in availability from the present.\n",
    "\n",
    "A detailed list of output formats can be found in the data product documentation here: https://coastwatch.pfeg.noaa.gov/erddap/griddap/documentation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a72757-da5b-4e1a-8eeb-18b9b62232e0",
   "metadata": {},
   "source": [
    "#### Source/Archive\n",
    "\n",
    "The data can be accessed via a REST API data access form. Here is the URL for manually querying the data: https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW.html\n",
    "\n",
    "This data source is maintained by the creator of the dataset, NOAA, indicating that this should be a reliable source of data for the foreseeable future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed98886-fd82-46d0-9a33-f21dee373a5f",
   "metadata": {},
   "source": [
    "#### Known issues with data quality\n",
    "\n",
    "NOAA satellite data sets have specified processing levels ranging from 0 to 4, with 0 indicating unprocessed telemetry data as received and 4 indicating data products that are model output or results from analysis derived from multiple measurements. The CoralTemp SST product is derived from three level-4 satellite datasets:\n",
    "  - NOAA/NESDIS operational near-real-time daily global 5-km geostationary-polar-orbiting (geo-polar) blended night-only SST analysis\n",
    "  - NOAA/NESDIS 2002-2016 reprocessed daily global 5-km geo-polar blended night-only SST analysis\n",
    "  - United Kingdom Met Office 1985-2002 daily global 5-km night-only SST reanalysis of Operational SST and Sea Ice Analysis (OSTIA)\n",
    "\n",
    "Thus, the data is gridded and gap-filled according to NOAA’s highest processing level. Therefore, there are no significant gaps in data, spatially or temporally, and all outliers and spikes are likely reflective of real world occurrences.\n",
    "\n",
    "Source: https://coralreefwatch.noaa.gov/product/5km/tutorial/crw05a_sst_product.php"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d5cb75-cb54-4708-8b88-459cae2ca17d",
   "metadata": {},
   "source": [
    "<a id='io'></a> \n",
    "### Dataset Input/Output \n",
    "\n",
    "Next, provide code to read in the data necessary for your analysis. This should be in the following order:\n",
    "\n",
    "1) Import all necessary packages (matplotlib, numpy, etc)\n",
    "\n",
    "2) Set any parameters that will be needed during subsequent portions of the notebook. Typical examples of parameters include:\n",
    "- names of any directories where data are stored\n",
    "- ranges of years over which data are valid\n",
    "- any thresholds or latitude/longitude ranges to be used later (e.g. dimensions of NINO3.4 region, threshold SSTA values for El Nino, etc.)\n",
    "\n",
    "3) Read in the data! If the data files are very large, you may want to consider subsetting the portion of files to be read in (see examples of this during notebooks provided in Weeks 7 and 8).\n",
    "\n",
    "_Since we will be running these notebooks in class during Weeks 9 and 10_, here is a good rule of thumb: It's good to aim for a relatively short amount of time needed to read in the data, since otherwise we'll be sitting around waiting for things to load for a long time. A  minute or two for data I/O is probably the max you'll want to target!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30253e61-0707-4540-9c86-9afc6df27958",
   "metadata": {},
   "source": [
    "<a id='display'></a> \n",
    "### Metadata Display and Basic Visualization\n",
    "\n",
    "Next, provide some example commands to take a quick look at what is in your dataset. We've done some things along these lines in class by now, but you should include at least one of:\n",
    "\n",
    "- Metadata display: commands to indicate a) which variables are included in the dataset and their names; b) coordinate information associated with the data variables; c) other important metadata parameters (site names, etc); and d) any important information on missing data\n",
    "- Basic visualization: a \"quick and dirty\" plot showing generally what the data look like. Depending on your dataset, this could be either a time series or a map (no fancy coordinate reference system/projection needed yet)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62354cdf-609f-487d-be51-9ea306997a69",
   "metadata": {},
   "source": [
    "<a id='usecases'></a> \n",
    "### Use Case Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5b04a9-b2bb-40ed-bb8c-9c75d3494c38",
   "metadata": {},
   "source": [
    "This is the \"meat\" of the notebook, and what will take the majority of the time to present in class. This section should provide:\n",
    "1) A plain-text summary (1-2 paragraphs) of the use case example you have chosen: include the target users and audience, and potential applicability. For example, the Week 7 SST exercise might discuss how the state of the ENSO system can be important for seasonal weather forecasts/coral bleaching outlooks, then mention the typical diagnostics associated with ENSO (i.e. identification of El Nino/La Nina events).\n",
    "\n",
    "2) Markdown and code blocks demonstrating how one walks through the desired use case example. This should be similar to the labs we've done in class: you might want to demonstrate how to isolate a particularly interesting time period, then create an image showing a feature you're interested in, for example.\n",
    "\n",
    "3) A discussion of the results and how they might be extended on further analysis. For example, we are doing El Nino/La Nina composites in class; a natural extension might be to look at individual events to see what their particular impacts were. Or if there are data quality issues which impact the results, you could discuss how these might be mitigated with additional information/analysis.\n",
    "\n",
    "Just keep in mind, you'll have roughly 20 minutes for your full presentation, and that goes surprisingly quickly! Probably 2-3 diagnostics is the most you'll be able to get through (you could try practicing with your group members to get a sense of timing).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d07de0d-1e81-442a-a895-7b7fd7906385",
   "metadata": {},
   "source": [
    "<a id='binder'></a> \n",
    "### Create Binder Environment\n",
    "\n",
    "The last step is to create a Binder environment for your project, so that we don't have to spend time configuring everyone's environment each time we switch between group presentations. Instructions are below:\n",
    "\n",
    " - Assemble all of the data needed in your Github repo: Jupyter notebooks, a README file, and any datasets needed (these should be small, if included within the repo). Larger datasets should be stored on a separate server, and access codes included within the Jupyter notebook as discussed above. \n",
    " \n",
    " - Create an _environment_ file: this is a text file which contains information on the packages needed in order to execute your code. The filename should be \"environment.yml\": an example that you can use for the proper syntax is included in this template repo. To determine which packages to include, you'll probably want to start by displaying the packages loaded in your environment: you can use the command `conda list -n [environment_name]` to get a list.\n",
    " \n",
    " More information on environment files can be found here:\n",
    " https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#\n",
    "\n",
    " - Create Binder. Use http://mybinder.org to create a  URL for your notebook Binder (you will need to enter your GitHub repo URL). You can also add a Launch Binder button directly to your GitHub repo, by including the following in your README.md:\n",
    "\n",
    "```\n",
    "launch with myBinder\n",
    "[![Binder](https://mybinder.org/badge.svg)](https://mybinder.org/v2/gh/<path to your repo>)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62c774b-8a7c-4f47-9c07-7f9823c48473",
   "metadata": {},
   "source": [
    "<a id='references'></a> \n",
    "### References\n",
    "\n",
    "List relevant references. Here are some additional resources on creating professional, shareable notebooks you may find useful:\n",
    "\n",
    "1. Notebook sharing guidelines from reproducible-science-curriculum: https://reproducible-science-curriculum.github.io/publication-RR-Jupyter/\n",
    "2. Guide for developing shareable notebooks by Kevin Coakley, SDSC: https://github.com/kevincoakley/sharing-jupyter-notebooks/raw/master/Jupyter-Notebooks-Sharing-Recommendations.pdf\n",
    "3. Guide for sharing notebooks by Andrea Zonca, SDSC: https://zonca.dev/2020/09/how-to-share-jupyter-notebooks.html\n",
    "4. Jupyter Notebook Best Practices: https://towardsdatascience.com/jupyter-notebook-best-practices-f430a6ba8c69\n",
    "5. Introduction to Jupyter templates nbextension: https://towardsdatascience.com/stop-copy-pasting-notebooks-embrace-jupyter-templates-6bd7b6c00b94  \n",
    "    5.1. Table of Contents (Toc2) readthedocs: https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/toc2/README.html  \n",
    "    5.2. Steps to install toc2: https://stackoverflow.com/questions/23435723/installing-ipython-notebook-table-of-contents\n",
    "6. Rule A, Birmingham A, Zuniga C, Altintas I, Huang SC, et al. (2019) Ten simple rules for writing and sharing computational analyses in Jupyter Notebooks. PLOS Computational Biology 15(7): e1007007. https://doi.org/10.1371/journal.pcbi.1007007. Supplementary materials: example notebooks (https://github.com/jupyter-guide/ten-rules-jupyter) and tutorial (https://github.com/ISMB-ECCB-2019-Tutorial-AM4/reproducible-computational-workflows)\n",
    "7. Languages supported by Jupyter kernels: https://github.com/jupyter/jupyter/wiki/Jupyter-kernels\n",
    "8. EarthCube notebooks presented at EC Annual Meeting 2020: https://www.earthcube.org/notebooks\n",
    "9. Manage your Python Virtual Environment with Conda: https://towardsdatascience.com/manage-your-python-virtual-environment-with-conda-a0d2934d5195\n",
    "10. Venv - Creation of Virtual Environments: https://docs.python.org/3/library/venv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f10df5-100c-4f4a-a1c3-bd417b524a61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
